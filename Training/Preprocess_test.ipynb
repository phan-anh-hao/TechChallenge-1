{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Asus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import nltk as nltk\n",
    "from word2number import w2n\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from collections import Counter\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nltk.download('wordnet')\n",
    "python -m spacy download en_core_web_sm\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = \"\"\n",
    "question = \"How many seven billion people have a salary greater than one hundred ?\"\n",
    "sql = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_text_number(text):\n",
    "\n",
    "    tagged_number_words = 'billion/CD million/CD ten/CD thousand/CD nine/CD hundred/CD ninety/CD eight/CD seven/CD six/CD five/CD four/CD three/CD two/CD one/CD eighty/CD seventy/CD sixty/CD fifty/CD forty/CD thirty/CD twenty/CD nineteen/CD eighteen/CD seventeen/CD sixteen/CD fifteen/CD fourteen/CD thirteen/CD twelve/CD eleven/CD zero/CD'\n",
    "    tagged_number_words_tuples = [nltk.tag.str2tuple(t) for t in tagged_number_words.split()]\n",
    "    my_tagger = nltk.UnigramTagger([ tagged_number_words_tuples ], backoff=nltk.DefaultTagger('IGNORE'))\n",
    "\n",
    "    my_grammar = 'NumberWord: {<CD>+}'\n",
    "    parser = nltk.RegexpParser(my_grammar)\n",
    "    parsed = parser.parse(my_tagger.tag(nltk.word_tokenize(text.lower())))\n",
    "    #print(parsed)\n",
    "\n",
    "    for tag in [tree.leaves() for tree in parsed.subtrees() if tree.label() == 'NumberWord']:\n",
    "        ut = nltk.untag(tag)\n",
    "        num = w2n.word_to_num(' '.join(ut))\n",
    "\n",
    "        r = re.compile(re.escape(' '.join(ut)), re.IGNORECASE)\n",
    "        text = r.sub(str(num), text)\n",
    "\n",
    "    #print('-- AFTER --')\n",
    "    return text\n",
    "\n",
    "def number_treatment_process(schema = \"\", question = \"\", sql = \"\"):\n",
    "    question_process = replace_text_number(question)\n",
    "    return schema, question_process, sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('', 'How many 7000000000 people have a salary greater than 100 ?', '')\n"
     ]
    }
   ],
   "source": [
    "print(number_treatment_process(question = question))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemming_process(schema = \"\", question = \"\", sql = \"\"):\n",
    "    question_split = question.split()\n",
    "    o = []\n",
    "    for word in question_split:\n",
    "        try:\n",
    "            o += [str(WordNetLemmatizer().lemmatize(word,'v'))]\n",
    "        except ValueError:\n",
    "            o += [word] \n",
    "\n",
    "    question_process = ' '.join(o)\n",
    "    return schema, question_process, sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How work work\n"
     ]
    }
   ],
   "source": [
    "test = \"How worked working\"\n",
    "print(stemming_process(question = test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Surrounding Entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def surrounding_entity_process(schema = \"\",question = \"\", sql = \"\"):\n",
    "    doc = nlp(question)\n",
    "    entities = doc.ents\n",
    "    question_process = question\n",
    "    for word in entities:\n",
    "        question_process = question_process.replace(str(word),\"'\"+str(word)+\"'\")\n",
    "\n",
    "    return schema, question_process, sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('', \"'Asean' and 'Twitter' and 'New York'\", '')\n"
     ]
    }
   ],
   "source": [
    "test = \"Asean and Twitter and New York\"\n",
    "print(surrounding_entity_process(question = test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Hao\n"
     ]
    }
   ],
   "source": [
    "a = \"Hao\"\n",
    "print(\"'\"+a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_redundant_field_words(schema, question, sql):\n",
    "    schema = schema.replace('_FIELD', '')\n",
    "    sql = sql.replace('_FIELD', '')\n",
    "    return schema, question, sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DIRECTION : TEXT, MANTRA : TEXT\n",
      "SELECT NAME FROM TABLE WHERE NAME_OF_THE_LAKE = 'LAGO DI LUZZONE'\n"
     ]
    }
   ],
   "source": [
    "schema = 'DIRECTION_FIELD : TEXT, MANTRA_FIELD : TEXT'\n",
    "question = ''\n",
    "sql = \"SELECT NAME_FIELD FROM TABLE WHERE NAME_OF_THE_LAKE_FIELD = 'LAGO DI LUZZONE'\"\n",
    "\n",
    "schema, question, sql = remove_redundant_field_words(schema, question, sql)\n",
    "\n",
    "print(schema)\n",
    "print(sql)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
